{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.metrics import mean_squared_error, r2_score, confusion_matrix, accuracy_score\n",
    "dt=pd.read_csv('amazon_product.csv')\n",
    "data = dt.drop(['Unnamed: 0','product_url','product_original_price' ,'product_availability' ,'product_photo', 'climate_pledge_friendly', 'sales_volume', 'delivery', 'unit_price', 'unit_count','asin'], axis=1)\n",
    "data['product_star_rating'] = pd.to_numeric(data['product_star_rating'], errors='coerce')\n",
    "data['product_star_rating']=data['product_star_rating'].fillna(data['product_star_rating'].median())\n",
    "\n",
    "def convert_dollar_number(dollar):\n",
    "    return float(dollar.replace('$',''))\n",
    "\n",
    "# data['product_price'] = data['product_price'].apply(convert_dollar_number)\n",
    "data['product_minimum_offer_price'] = data['product_minimum_offer_price'].apply(convert_dollar_number)\n",
    "data['product_price'] = data['product_price'].apply(convert_dollar_number)\n",
    "data['is_best_seller']=data['is_best_seller'].astype(int)\n",
    "data['is_amazon_choice']=data['is_amazon_choice'].astype(int)\n",
    "data['is_prime']=data['is_prime'].astype(int)\n",
    "data['has_variations']=data['has_variations'].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\WIN11\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\utils\\validation.py:1339: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "c:\\Users\\WIN11\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE: 0.5\n",
      "R2: -1.1333333333333333\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.67      0.40      0.50        10\n",
      "           1       0.40      0.67      0.50         6\n",
      "\n",
      "    accuracy                           0.50        16\n",
      "   macro avg       0.53      0.53      0.50        16\n",
      "weighted avg       0.57      0.50      0.50        16\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import mean_squared_error, r2_score, confusion_matrix, classification_report\n",
    "import seaborn as sns\n",
    "\n",
    "# Assuming your data preparation is correct:\n",
    "X = data.drop(['is_best_seller', 'product_title', 'currency'], axis=1)\n",
    "y = data[['is_best_seller']]\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, stratify=y, random_state=42)\n",
    "\n",
    "lr = LogisticRegression()\n",
    "lr.fit(X_train, y_train)\n",
    "y_pred = lr.predict(X_test)\n",
    "\n",
    "# Evaluate the model\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "\n",
    "# Plotting: Select a single feature from X_test for visualization (e.g., the first feature)\n",
    "plt.scatter(X_test.iloc[:, 0], y_test, label='Actual')\n",
    "plt.scatter(X_test.iloc[:, 0], y_pred, color='red', label='Predicted', marker='+')\n",
    "plt.xlabel(X.columns[0])\n",
    "plt.ylabel('is_best_seller')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "# Confusion Matrix\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues')\n",
    "plt.title('Confusion Matrix')\n",
    "plt.ylabel('Actual')\n",
    "plt.xlabel('Predicted')\n",
    "plt.show()\n",
    "\n",
    "# Print MSE and R2\n",
    "print('MSE:', mse)\n",
    "print('R2:', r2)\n",
    "\n",
    "# Additional Metrics\n",
    "print(classification_report(y_test, y_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters found:  {'solver': 'newton-cg', 'penalty': 'l2', 'l1_ratio': np.float64(0.3333333333333333), 'C': np.float64(0.001)}\n",
      "Best cross-validation accuracy: 0.69\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.71      0.50      0.59        10\n",
      "           1       0.44      0.67      0.53         6\n",
      "\n",
      "    accuracy                           0.56        16\n",
      "   macro avg       0.58      0.58      0.56        16\n",
      "weighted avg       0.61      0.56      0.57        16\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\WIN11\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py:540: FitFailedWarning: \n",
      "120 fits failed out of a total of 250.\n",
      "The score on these train-test partitions for these parameters will be set to nan.\n",
      "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "10 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\WIN11\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 888, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"c:\\Users\\WIN11\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\base.py\", line 1473, in wrapper\n",
      "    return fit_method(estimator, *args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\WIN11\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1194, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\WIN11\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 67, in _check_solver\n",
      "    raise ValueError(\n",
      "ValueError: Solver newton-cg supports only 'l2' or None penalties, got l1 penalty.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "15 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\WIN11\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 888, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"c:\\Users\\WIN11\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\base.py\", line 1473, in wrapper\n",
      "    return fit_method(estimator, *args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\WIN11\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1194, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\WIN11\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 67, in _check_solver\n",
      "    raise ValueError(\n",
      "ValueError: Solver sag supports only 'l2' or None penalties, got elasticnet penalty.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "7 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\WIN11\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 888, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"c:\\Users\\WIN11\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\base.py\", line 1466, in wrapper\n",
      "    estimator._validate_params()\n",
      "  File \"c:\\Users\\WIN11\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\base.py\", line 666, in _validate_params\n",
      "    validate_parameter_constraints(\n",
      "  File \"c:\\Users\\WIN11\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\utils\\_param_validation.py\", line 95, in validate_parameter_constraints\n",
      "    raise InvalidParameterError(\n",
      "sklearn.utils._param_validation.InvalidParameterError: The 'penalty' parameter of LogisticRegression must be a str among {'l1', 'elasticnet', 'l2'} or None. Got 'none' instead.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "4 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\WIN11\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 888, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"c:\\Users\\WIN11\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\base.py\", line 1466, in wrapper\n",
      "    estimator._validate_params()\n",
      "  File \"c:\\Users\\WIN11\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\base.py\", line 666, in _validate_params\n",
      "    validate_parameter_constraints(\n",
      "  File \"c:\\Users\\WIN11\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\utils\\_param_validation.py\", line 95, in validate_parameter_constraints\n",
      "    raise InvalidParameterError(\n",
      "sklearn.utils._param_validation.InvalidParameterError: The 'penalty' parameter of LogisticRegression must be a str among {'l1', 'l2', 'elasticnet'} or None. Got 'none' instead.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "7 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\WIN11\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 888, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"c:\\Users\\WIN11\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\base.py\", line 1466, in wrapper\n",
      "    estimator._validate_params()\n",
      "  File \"c:\\Users\\WIN11\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\base.py\", line 666, in _validate_params\n",
      "    validate_parameter_constraints(\n",
      "  File \"c:\\Users\\WIN11\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\utils\\_param_validation.py\", line 95, in validate_parameter_constraints\n",
      "    raise InvalidParameterError(\n",
      "sklearn.utils._param_validation.InvalidParameterError: The 'penalty' parameter of LogisticRegression must be a str among {'l2', 'elasticnet', 'l1'} or None. Got 'none' instead.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "10 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\WIN11\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 888, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"c:\\Users\\WIN11\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\base.py\", line 1473, in wrapper\n",
      "    return fit_method(estimator, *args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\WIN11\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1194, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\WIN11\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 67, in _check_solver\n",
      "    raise ValueError(\n",
      "ValueError: Solver lbfgs supports only 'l2' or None penalties, got elasticnet penalty.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "10 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\WIN11\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 888, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"c:\\Users\\WIN11\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\base.py\", line 1473, in wrapper\n",
      "    return fit_method(estimator, *args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\WIN11\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1194, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\WIN11\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 67, in _check_solver\n",
      "    raise ValueError(\n",
      "ValueError: Solver sag supports only 'l2' or None penalties, got l1 penalty.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "11 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\WIN11\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 888, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"c:\\Users\\WIN11\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\base.py\", line 1466, in wrapper\n",
      "    estimator._validate_params()\n",
      "  File \"c:\\Users\\WIN11\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\base.py\", line 666, in _validate_params\n",
      "    validate_parameter_constraints(\n",
      "  File \"c:\\Users\\WIN11\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\utils\\_param_validation.py\", line 95, in validate_parameter_constraints\n",
      "    raise InvalidParameterError(\n",
      "sklearn.utils._param_validation.InvalidParameterError: The 'penalty' parameter of LogisticRegression must be a str among {'elasticnet', 'l1', 'l2'} or None. Got 'none' instead.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "3 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\WIN11\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 888, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"c:\\Users\\WIN11\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\base.py\", line 1466, in wrapper\n",
      "    estimator._validate_params()\n",
      "  File \"c:\\Users\\WIN11\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\base.py\", line 666, in _validate_params\n",
      "    validate_parameter_constraints(\n",
      "  File \"c:\\Users\\WIN11\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\utils\\_param_validation.py\", line 95, in validate_parameter_constraints\n",
      "    raise InvalidParameterError(\n",
      "sklearn.utils._param_validation.InvalidParameterError: The 'penalty' parameter of LogisticRegression must be a str among {'l2', 'l1', 'elasticnet'} or None. Got 'none' instead.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "20 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\WIN11\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 888, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"c:\\Users\\WIN11\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\base.py\", line 1473, in wrapper\n",
      "    return fit_method(estimator, *args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\WIN11\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1194, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\WIN11\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 75, in _check_solver\n",
      "    raise ValueError(\n",
      "ValueError: Only 'saga' solver supports elasticnet penalty, got solver=liblinear.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "5 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\WIN11\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 888, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"c:\\Users\\WIN11\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\base.py\", line 1473, in wrapper\n",
      "    return fit_method(estimator, *args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\WIN11\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1194, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\WIN11\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 67, in _check_solver\n",
      "    raise ValueError(\n",
      "ValueError: Solver lbfgs supports only 'l2' or None penalties, got l1 penalty.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "15 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\WIN11\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 888, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"c:\\Users\\WIN11\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\base.py\", line 1473, in wrapper\n",
      "    return fit_method(estimator, *args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\WIN11\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1194, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\WIN11\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 67, in _check_solver\n",
      "    raise ValueError(\n",
      "ValueError: Solver newton-cg supports only 'l2' or None penalties, got elasticnet penalty.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "3 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\WIN11\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 888, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"c:\\Users\\WIN11\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\base.py\", line 1466, in wrapper\n",
      "    estimator._validate_params()\n",
      "  File \"c:\\Users\\WIN11\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\base.py\", line 666, in _validate_params\n",
      "    validate_parameter_constraints(\n",
      "  File \"c:\\Users\\WIN11\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\utils\\_param_validation.py\", line 95, in validate_parameter_constraints\n",
      "    raise InvalidParameterError(\n",
      "sklearn.utils._param_validation.InvalidParameterError: The 'penalty' parameter of LogisticRegression must be a str among {'elasticnet', 'l2', 'l1'} or None. Got 'none' instead.\n",
      "\n",
      "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
      "c:\\Users\\WIN11\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\model_selection\\_search.py:1102: UserWarning: One or more of the test scores are non-finite: [       nan        nan        nan 0.66888889 0.62666667        nan\n",
      "        nan        nan 0.68888889        nan        nan        nan\n",
      "        nan 0.62666667 0.62666667        nan 0.64666667 0.62666667\n",
      " 0.66888889        nan 0.62666667 0.62666667        nan        nan\n",
      " 0.66888889        nan        nan 0.62666667        nan 0.62666667\n",
      " 0.62666667 0.62666667        nan 0.56444444        nan        nan\n",
      " 0.62666667        nan        nan 0.62666667 0.62666667 0.56444444\n",
      "        nan 0.62444444 0.62666667 0.62666667 0.56444444 0.62666667\n",
      "        nan 0.62666667]\n",
      "  warnings.warn(\n",
      "c:\\Users\\WIN11\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1197: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "c:\\Users\\WIN11\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\utils\\validation.py:1339: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "c:\\Users\\WIN11\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_linesearch.py:312: LineSearchWarning: The line search algorithm did not converge\n",
      "  alpha_star, phi_star, old_fval, derphi_star = scalar_search_wolfe2(\n",
      "c:\\Users\\WIN11\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\utils\\optimize.py:99: LineSearchWarning: The line search algorithm did not converge\n",
      "  ret = line_search_wolfe2(\n"
     ]
    }
   ],
   "source": [
    "X = data.drop(['is_best_seller', 'product_title', 'currency'], axis=1)\n",
    "y = data[['is_best_seller']]\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, stratify=y, random_state=42)\n",
    "model = LogisticRegression(max_iter=10000)\n",
    "\n",
    "# Define the hyperparameters to tune using distributions for random search\n",
    "param_dist = {\n",
    "    'penalty': ['l1', 'l2', 'elasticnet', 'none'],\n",
    "    'C': np.logspace(-3, 3, 10),\n",
    "    'solver': ['newton-cg', 'lbfgs', 'liblinear', 'sag', 'saga'],\n",
    "    'l1_ratio': np.linspace(0, 1, 10)  # Only used for elasticnet penalty\n",
    "}\n",
    "\n",
    "# Create the RandomizedSearchCV object\n",
    "random_search = RandomizedSearchCV(estimator=model, param_distributions=param_dist, n_iter=50, cv=5, scoring='accuracy', n_jobs=-1, random_state=42)\n",
    "\n",
    "# Fit the model to the training data\n",
    "random_search.fit(X_train, y_train)\n",
    "\n",
    "# Print the best parameters and the best score\n",
    "print(\"Best parameters found: \", random_search.best_params_)\n",
    "print(\"Best cross-validation accuracy: {:.2f}\".format(random_search.best_score_))\n",
    "\n",
    "# Evaluate the best model on the test set\n",
    "best_model = random_search.best_estimator_\n",
    "y_pred = best_model.predict(X_test)\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\WIN11\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py:540: FitFailedWarning: \n",
      "65 fits failed out of a total of 250.\n",
      "The score on these train-test partitions for these parameters will be set to nan.\n",
      "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "28 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\WIN11\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 888, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"c:\\Users\\WIN11\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\base.py\", line 1466, in wrapper\n",
      "    estimator._validate_params()\n",
      "  File \"c:\\Users\\WIN11\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\base.py\", line 666, in _validate_params\n",
      "    validate_parameter_constraints(\n",
      "  File \"c:\\Users\\WIN11\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\utils\\_param_validation.py\", line 95, in validate_parameter_constraints\n",
      "    raise InvalidParameterError(\n",
      "sklearn.utils._param_validation.InvalidParameterError: The 'max_features' parameter of DecisionTreeClassifier must be an int in the range [1, inf), a float in the range (0.0, 1.0], a str among {'log2', 'sqrt'} or None. Got 'auto' instead.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "37 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\WIN11\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 888, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"c:\\Users\\WIN11\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\base.py\", line 1466, in wrapper\n",
      "    estimator._validate_params()\n",
      "  File \"c:\\Users\\WIN11\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\base.py\", line 666, in _validate_params\n",
      "    validate_parameter_constraints(\n",
      "  File \"c:\\Users\\WIN11\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\utils\\_param_validation.py\", line 95, in validate_parameter_constraints\n",
      "    raise InvalidParameterError(\n",
      "sklearn.utils._param_validation.InvalidParameterError: The 'max_features' parameter of DecisionTreeClassifier must be an int in the range [1, inf), a float in the range (0.0, 1.0], a str among {'sqrt', 'log2'} or None. Got 'auto' instead.\n",
      "\n",
      "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
      "c:\\Users\\WIN11\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\model_selection\\_search.py:1102: UserWarning: One or more of the test scores are non-finite: [0.64888889        nan 0.54666667 0.58666667        nan 0.58666667\n",
      "        nan        nan 0.56666667 0.62666667 0.54222222 0.62666667\n",
      " 0.37333333 0.58666667 0.60666667 0.60666667 0.62666667 0.62666667\n",
      " 0.62666667        nan 0.62666667 0.52888889        nan 0.37333333\n",
      " 0.62666667 0.58666667        nan 0.58666667 0.62666667 0.41777778\n",
      " 0.60444444        nan        nan 0.62666667        nan 0.60888889\n",
      " 0.64666667 0.60888889 0.52444444        nan 0.64888889 0.44\n",
      " 0.37333333 0.37333333        nan 0.60888889 0.52222222 0.56666667\n",
      " 0.41777778        nan]\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters found:  {'splitter': 'best', 'min_samples_split': 5, 'min_samples_leaf': 2, 'min_impurity_decrease': 0.01, 'max_leaf_nodes': 20, 'max_features': None, 'max_depth': 40, 'criterion': 'entropy', 'class_weight': 'balanced', 'ccp_alpha': np.float64(0.03333333333333333)}\n",
      "Best cross-validation accuracy: 0.65\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.71      0.50      0.59        10\n",
      "           1       0.44      0.67      0.53         6\n",
      "\n",
      "    accuracy                           0.56        16\n",
      "   macro avg       0.58      0.58      0.56        16\n",
      "weighted avg       0.61      0.56      0.57        16\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "X = data.drop(['is_best_seller', 'product_title', 'currency'], axis=1)\n",
    "y = data[['is_best_seller']]\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, stratify=y, random_state=42)\n",
    "model = DecisionTreeClassifier()\n",
    "\n",
    "# Define the hyperparameters to tune using distributions for random search\n",
    "param_dist = {\n",
    "    'criterion': ['gini', 'entropy'],\n",
    "    'splitter': ['best', 'random'],\n",
    "    'max_depth': [None, 10, 20, 30, 40, 50],\n",
    "    'min_samples_split': [2, 5, 10],\n",
    "    'min_samples_leaf': [1, 2, 4],\n",
    "    'max_features': [None, 'auto', 'sqrt', 'log2'],\n",
    "    'class_weight': [None, 'balanced'],\n",
    "    'max_leaf_nodes': [None, 10, 20, 30, 40, 50],\n",
    "    'min_impurity_decrease': [0.0, 0.01, 0.1],\n",
    "    'ccp_alpha': np.linspace(0, 0.1, 10)\n",
    "}\n",
    "\n",
    "# Create the RandomizedSearchCV object\n",
    "random_search = RandomizedSearchCV(estimator=model, param_distributions=param_dist, n_iter=50, cv=5, scoring='accuracy', n_jobs=-1, random_state=42)\n",
    "\n",
    "# Fit the model to the training data\n",
    "random_search.fit(X_train, y_train)\n",
    "\n",
    "# Print the best parameters and the best score\n",
    "print(\"Best parameters found: \", random_search.best_params_)\n",
    "print(\"Best cross-validation accuracy: {:.2f}\".format(random_search.best_score_))\n",
    "\n",
    "# Evaluate the best model on the test set\n",
    "best_model = random_search.best_estimator_\n",
    "y_pred = best_model.predict(X_test)\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\WIN11\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py:540: FitFailedWarning: \n",
      "45 fits failed out of a total of 250.\n",
      "The score on these train-test partitions for these parameters will be set to nan.\n",
      "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "19 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\WIN11\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 888, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"c:\\Users\\WIN11\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\base.py\", line 1466, in wrapper\n",
      "    estimator._validate_params()\n",
      "  File \"c:\\Users\\WIN11\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\base.py\", line 666, in _validate_params\n",
      "    validate_parameter_constraints(\n",
      "  File \"c:\\Users\\WIN11\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\utils\\_param_validation.py\", line 95, in validate_parameter_constraints\n",
      "    raise InvalidParameterError(\n",
      "sklearn.utils._param_validation.InvalidParameterError: The 'max_features' parameter of RandomForestClassifier must be an int in the range [1, inf), a float in the range (0.0, 1.0], a str among {'sqrt', 'log2'} or None. Got 'auto' instead.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "26 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\WIN11\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 888, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"c:\\Users\\WIN11\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\base.py\", line 1466, in wrapper\n",
      "    estimator._validate_params()\n",
      "  File \"c:\\Users\\WIN11\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\base.py\", line 666, in _validate_params\n",
      "    validate_parameter_constraints(\n",
      "  File \"c:\\Users\\WIN11\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\utils\\_param_validation.py\", line 95, in validate_parameter_constraints\n",
      "    raise InvalidParameterError(\n",
      "sklearn.utils._param_validation.InvalidParameterError: The 'max_features' parameter of RandomForestClassifier must be an int in the range [1, inf), a float in the range (0.0, 1.0], a str among {'log2', 'sqrt'} or None. Got 'auto' instead.\n",
      "\n",
      "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
      "c:\\Users\\WIN11\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\model_selection\\_search.py:1102: UserWarning: One or more of the test scores are non-finite: [0.60444444 0.56666667 0.60444444 0.66888889 0.60666667        nan\n",
      " 0.58666667 0.62888889        nan 0.58222222 0.58444444 0.56222222\n",
      " 0.68888889 0.68666667 0.62444444 0.69111111        nan 0.64666667\n",
      " 0.58222222 0.60444444        nan 0.56666667 0.62444444 0.58222222\n",
      " 0.58222222 0.65111111 0.67111111 0.62666667 0.60888889        nan\n",
      " 0.52444444 0.62666667        nan 0.58222222 0.60666667 0.62222222\n",
      "        nan        nan 0.64666667 0.64888889 0.64666667 0.62888889\n",
      " 0.56666667 0.62888889 0.64888889 0.64888889 0.58666667 0.56444444\n",
      "        nan 0.64444444]\n",
      "  warnings.warn(\n",
      "c:\\Users\\WIN11\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\base.py:1473: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters found:  {'n_estimators': 500, 'min_samples_split': 5, 'min_samples_leaf': 1, 'max_features': 'sqrt', 'max_depth': None, 'criterion': 'gini', 'class_weight': 'balanced', 'ccp_alpha': np.float64(0.011111111111111112), 'bootstrap': False}\n",
      "Best cross-validation accuracy: 0.69\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.86      0.60      0.71        10\n",
      "           1       0.56      0.83      0.67         6\n",
      "\n",
      "    accuracy                           0.69        16\n",
      "   macro avg       0.71      0.72      0.69        16\n",
      "weighted avg       0.74      0.69      0.69        16\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "X = data.drop(['is_best_seller', 'product_title', 'currency'], axis=1)\n",
    "y = data[['is_best_seller']]\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, stratify=y, random_state=42)\n",
    "model = RandomForestClassifier()\n",
    "\n",
    "# Define the hyperparameters to tune using distributions for random search\n",
    "param_dist = {\n",
    "    'n_estimators': [50, 100, 200, 300, 400, 500],\n",
    "    'criterion': ['gini', 'entropy'],  # Criterion to measure the quality of a split\n",
    "    'max_depth': [None, 10, 20, 30, 40, 50],  # Maximum depth of the tree\n",
    "    'min_samples_split': [2, 5, 10],  # Minimum number of samples required to split an internal node\n",
    "    'min_samples_leaf': [1, 2, 4],  # Minimum number of samples required to be at a leaf node\n",
    "    'max_features': [None, 'auto', 'sqrt', 'log2'],  # Number of features to consider when looking for the best split\n",
    "    'bootstrap': [True, False],  # Whether bootstrap samples are used when building trees\n",
    "    'class_weight': [None, 'balanced'],  # Weights associated with classes\n",
    "    'ccp_alpha': np.linspace(0, 0.1, 10)  # Complexity parameter used for Minimal Cost-Complexity Pruning\n",
    "}\n",
    "\n",
    "# Create the RandomizedSearchCV object\n",
    "random_search = RandomizedSearchCV(estimator=model, param_distributions=param_dist, n_iter=50, cv=5, scoring='accuracy', n_jobs=-1, random_state=42)\n",
    "\n",
    "# Fit the model to the training data\n",
    "random_search.fit(X_train, y_train)\n",
    "\n",
    "# Print the best parameters and the best score\n",
    "print(\"Best parameters found: \", random_search.best_params_)\n",
    "print(\"Best cross-validation accuracy: {:.2f}\".format(random_search.best_score_))\n",
    "\n",
    "# Evaluate the best model on the test set\n",
    "best_model = random_search.best_estimator_\n",
    "y_pred = best_model.predict(X_test)\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] There are no meaningful features which satisfy the provided configuration. Decreasing Dataset parameters min_data_in_bin or min_data_in_leaf and re-constructing Dataset might resolve this warning.\n",
      "[LightGBM] [Info] Number of positive: 18, number of negative: 30\n",
      "[LightGBM] [Info] Total Bins 0\n",
      "[LightGBM] [Info] Number of data points in the train set: 48, number of used features: 0\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "[LightGBM] [Info] Start training from score 0.000000\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "Best parameters found:  {'subsample': 0.6, 'num_leaves': 50, 'n_estimators': 100, 'min_child_samples': 50, 'max_depth': 30, 'learning_rate': 0.3, 'colsample_bytree': 1.0}\n",
      "Best cross-validation accuracy: 0.63\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00        10\n",
      "           1       0.38      1.00      0.55         6\n",
      "\n",
      "    accuracy                           0.38        16\n",
      "   macro avg       0.19      0.50      0.27        16\n",
      "weighted avg       0.14      0.38      0.20        16\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\WIN11\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\preprocessing\\_label.py:97: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "c:\\Users\\WIN11\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\preprocessing\\_label.py:132: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, dtype=self.classes_.dtype, warn=True)\n",
      "c:\\Users\\WIN11\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "c:\\Users\\WIN11\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "c:\\Users\\WIN11\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    }
   ],
   "source": [
    "import lightgbm as lgb\n",
    "X = data.drop(['is_best_seller', 'product_title', 'currency'], axis=1)\n",
    "y = data[['is_best_seller']]\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, stratify=y, random_state=42)\n",
    "\n",
    "# Initialize the LightGBM classifier\n",
    "model = lgb.LGBMClassifier(class_weight='balanced')\n",
    "\n",
    "# Define the hyperparameters to tune using distributions for random search\n",
    "param_dist = {\n",
    "    'num_leaves': [31, 50, 100],\n",
    "    'max_depth': [-1, 10, 20, 30],\n",
    "    'learning_rate': [0.001, 0.01, 0.1, 0.3],\n",
    "    'n_estimators': [100, 200, 500],\n",
    "    'subsample': [0.6, 0.8, 1.0],\n",
    "    'colsample_bytree': [0.6, 0.8, 1.0],\n",
    "    'min_child_samples': [20, 30, 50]\n",
    "}\n",
    "\n",
    "# Create the RandomizedSearchCV object\n",
    "random_search = RandomizedSearchCV(estimator=model, param_distributions=param_dist, n_iter=50, cv=5, scoring='accuracy', n_jobs=-1, random_state=42)\n",
    "\n",
    "# Fit the model to the training data\n",
    "random_search.fit(X_train, y_train)\n",
    "\n",
    "# Print the best parameters and the best score\n",
    "print(\"Best parameters found: \", random_search.best_params_)\n",
    "print(\"Best cross-validation accuracy: {:.2f}\".format(random_search.best_score_))\n",
    "\n",
    "# Evaluate the best model on the test set\n",
    "best_model = random_search.best_estimator_\n",
    "y_pred = best_model.predict(X_test)\n",
    "print(classification_report(y_test, y_pred))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
